{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "id": "ebPAAZR1dt2I",
    "outputId": "19d42762-943e-467a-9046-95a43a138a52"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "this code shows the implementation of graphlet_sampling kernel ( which is expected to have the higher accuracy\n",
    "than random features_based kernels, but much longer computational time)\n",
    "'''\n",
    "#!pip install grakel \n",
    "import time \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import networkx as nx\n",
    "import grakel as gk \n",
    "\n",
    "from grakel.datasets import fetch_dataset\n",
    "from grakel.kernels import ShortestPath\n",
    "from grakel.kernels import GraphletSampling\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "doklTJ5bdwMB"
   },
   "outputs": [],
   "source": [
    "# DataSet Loading \n",
    "\n",
    "class dataset_loading:\n",
    "    def __init__(self):\n",
    "        pass \n",
    "    #mutag dataset\n",
    "    def mutag(self,test_size=0.1):\n",
    "        Gnx_train=[];\n",
    "        Gnx_test=[];\n",
    "        MUTAG = fetch_dataset(\"MUTAG\", verbose=False,as_graphs=False)\n",
    "        G, y = MUTAG.data, MUTAG.target\n",
    "        G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=0.1)\n",
    "        for i in range(len(G_train)):\n",
    "            g_current=nx.Graph(list(G_train[i][2]));\n",
    "            g_current.add_nodes_from(G_train[i][1])\n",
    "            Gnx_train.append(g_current)\n",
    "        for i in range(len(G_test)):\n",
    "            g_current=nx.Graph(list(G_test[i][2]));\n",
    "            g_current.add_nodes_from(G_test[i][1])\n",
    "            Gnx_test.append(g_current)\n",
    "        return (Gnx_train,y_train), (Gnx_test,y_test)\n",
    "\n",
    "    #SBM generator\n",
    "    def generate_SBM(self,Graphs_num=300,nodes_per_graph=60,block_size=10,fraction=0.3,mult_factor=1.2,avg_deg=10,test_size=0.2):\n",
    "        blocks_num=int(nodes_per_graph/block_size)\n",
    "        sizes=[block_size]*blocks_num\n",
    "        G,y=[],[]\n",
    "        for i in range (Graphs_num):                  \n",
    "            p_in=fraction  if i <Graphs_num/2 else fraction*mult_factor\n",
    "            p_out=(avg_deg-(block_size-1)*p_in)/(nodes_per_graph-block_size)\n",
    "            p=p_out*np.ones([blocks_num]*2)+(p_in-p_out)*np.eye(blocks_num)\n",
    "            #print(p_in,p_out)\n",
    "            G_cur=nx.stochastic_block_model(sizes, p)\n",
    "            adj=[(i,j) for (i,j,_) in G_cur.edges(data=True)]\n",
    "            node_labels=dict ((i,list(val.values())[0]) for (i,val) in G_cur.nodes(data=True) )\n",
    "            \n",
    "            G.append(gk.Graph(adj, node_labels=node_labels))\n",
    "            y.append(-1 if i<Graphs_num/2 else 1)            \n",
    "        G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=test_size)\n",
    "        return (G_train,y_train),(G_test,y_test)\n",
    "        \n",
    "\n",
    "    # DD dataset\n",
    "    def DD(self,test_size=0.1,train_size=800):\n",
    "        DD = fetch_dataset(\"DD\", verbose=True)\n",
    "        G, y = DD.data, DD.target\n",
    "        Gnx_train=[];\n",
    "        Gnx_test=[];           # Taking just Train_size graphs of the data set as training set, \n",
    "                                       #this is due to the large computatational time\n",
    "        G_train, G_test, y_train, y_test = train_test_split(G, y, test_size=test_size)\n",
    "        G_train,y_train=G_train[0:Train_size], y_train[0:Train_size]\n",
    "        for i in range(len(G_train)):\n",
    "            g_current=nx.Graph(list(G_train[i][0]));\n",
    "            g_current.add_nodes_from(G_train[i][1])\n",
    "            Gnx_train.append(g_current)\n",
    "        for i in range(len(G_test)):\n",
    "            g_current=nx.Graph(list(G_test[i][0]));\n",
    "            g_current.add_nodes_from(G_test[i][1])\n",
    "            Gnx_test.append(g_current)\n",
    "        return (Gnx_train,y_train), (Gnx_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The graphlet sampling kernel :cite:`shervashidze2009efficient`.\"\"\"\n",
    "# Author: Ioannis Siglidis <y.siglidis@gmail.com>\n",
    "# License: BSD 3 clause\n",
    "import collections\n",
    "import math\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "from grakel.graph import Graph\n",
    "from grakel.kernels import Kernel\n",
    "from grakel.kernels._c_functions import ConSubg\n",
    "from grakel.kernels._isomorphism import Graph as bGraph\n",
    "\n",
    "# Python 2/3 cross-compatibility import\n",
    "from six import iteritems\n",
    "from six import itervalues\n",
    "from builtins import range\n",
    "\n",
    "class MyGraphletSampling(Kernel):\n",
    "    r\"\"\"The graphlet sampling kernel.\n",
    "\n",
    "    See :cite:`shervashidze2009efficient`.\n",
    "\n",
    "    If either \"delta\", \"epsilon\", \"a\" or \"n_samples\" is given calculates\n",
    "    the kernel value for the given (or derived) random picked n_samples, by\n",
    "    randomly sampling from k from 3 to 5.\n",
    "    Otherwise calculates the kernel value drawing all possible connected\n",
    "    samples of size k.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    random_state :  RandomState or int, default=None\n",
    "        A random number generator instance or an int to initialize a RandomState as a seed.\n",
    "\n",
    "    k : int, default=5\n",
    "        The dimension of the given graphlets.\n",
    "\n",
    "    sampling : None or dict\n",
    "        Defines if random sampling of graphlets will be utilised.\n",
    "        If not None the dictionary can either contain:\n",
    "\n",
    "            - n_samples : int\n",
    "                Sets the value of randomly drawn random samples,\n",
    "                from sizes between 3..k. Overides the parameters a, epsilon,\n",
    "                delta.\n",
    "        or\n",
    "\n",
    "            -  delta : float, default=0.05\n",
    "               Confidence level (typically 0.05 or 0.1).\n",
    "               For calculation of the number of samples achieving the certain\n",
    "               bound. n_samples argument must not be provided and for\n",
    "               initialising the default value either \"epsilon\" or\n",
    "               \"a\" must be set.\n",
    "\n",
    "            - epsilon : float, default=0.05\n",
    "                Precision level (typically 0.05 or 0.1).\n",
    "                For calculation of the number of samples achieving the certain\n",
    "                bound. n_samples argument must not be provided and for\n",
    "                initialising the default value either \"delta\" or\n",
    "                \"a\" must be set.\n",
    "\n",
    "            - a : int\n",
    "                Number of isomorphism classes of graphlets.\n",
    "                If -1 the number is the maximum possible, from a database\n",
    "                1 until 9 or else predicted through interpolation.\n",
    "                For calculation of the number of samples achieving the certain\n",
    "                bound. n_samples argument must not be provided and for\n",
    "                initializing the default value either \"delta\" or \"epsilon\" must\n",
    "                be set.\n",
    "\n",
    "\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    X : dict\n",
    "        A dictionary of pairs between each input graph and a bins where the\n",
    "        sampled graphlets have fallen.\n",
    "\n",
    "    sample_graphlets_ : function\n",
    "        A function taking as input a binary adjacency matrix, parametrised\n",
    "        to work for the certain samples, k and deterministic/propabilistic\n",
    "        mode.\n",
    "\n",
    "    random_state_ : RandomState\n",
    "        A RandomState object handling all randomness of the class.\n",
    "\n",
    "    _graph_bins : dict\n",
    "        A dictionary of graph bins holding pynauty objects\n",
    "\n",
    "    _nx : int\n",
    "        Holds the number of sampled X graphs.\n",
    "\n",
    "    _ny : int\n",
    "        Holds the number of sampled Y graphs.\n",
    "\n",
    "    _X_diag : np.array, shape=(_nx, 1)\n",
    "        Holds the diagonal of X kernel matrix in a numpy array, if calculated\n",
    "        (`fit_transform`).\n",
    "\n",
    "    _phi_X : np.array, shape=(_nx, len(_graph_bins))\n",
    "        Holds the features of X in a numpy array, if calculated.\n",
    "        (`fit_transform`).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    _graph_format = \"adjacency\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_jobs=None,\n",
    "                 normalize=False, verbose=False,\n",
    "                 random_state=None,\n",
    "                 k=5,\n",
    "                 sampling=None):\n",
    "        \"\"\"Initialise a subtree_wl kernel.\"\"\"\n",
    "        super(MyGraphletSampling, self).__init__(n_jobs=n_jobs,\n",
    "                                               normalize=normalize,\n",
    "                                               verbose=verbose)\n",
    "\n",
    "        self.random_state = random_state\n",
    "        self.k = k\n",
    "        self.sampling = sampling\n",
    "        self._initialized.update({\"random_state\": False, \"k\": False, \"sampling\": False})\n",
    "\n",
    "\n",
    "    def initialize(self):\n",
    "        \"\"\"Initialize all transformer arguments, needing initialization.\"\"\"\n",
    "        self._graph_bins = dict()\n",
    "        if not self._initialized[\"n_jobs\"]:\n",
    "            if self.n_jobs is not None:\n",
    "                warnings.warn('no implemented parallelization for GraphletSampling')\n",
    "            self._initialized[\"n_jobs\"] = True\n",
    "\n",
    "        if not self._initialized[\"random_state\"]:\n",
    "            self.random_state_ = check_random_state(self.random_state)\n",
    "            self._initialized[\"random_state\"] = True\n",
    "\n",
    "        if not self._initialized[\"k\"]:\n",
    "            if type(self.k) is not int:\n",
    "                raise TypeError('k must be an int')\n",
    "\n",
    "            if self.k > 10:\n",
    "                warnings.warn('graphlets are too big - '\n",
    "                              'computation may be slow')\n",
    "            elif self.k < 3:\n",
    "                raise TypeError('k must be bigger than 3')\n",
    "\n",
    "            self._initialized[\"k\"] = True\n",
    "\n",
    "        if not self._initialized[\"sampling\"]:\n",
    "            sampling = self.sampling\n",
    "            k = self.k\n",
    "            if sampling is None:\n",
    "                n_samples = None\n",
    "\n",
    "                def sample_graphlets(A, k, *args):\n",
    "                    return sample_graphlets_all_connected(A, k)\n",
    "            elif type(sampling) is dict:\n",
    "                if \"n_samples\" in sampling:\n",
    "                    # Get the number of samples\n",
    "                    n_samples = sampling[\"n_samples\"]\n",
    "\n",
    "                    # Display a warning if arguments ignored\n",
    "                    args = [arg for arg in [\"delta\", \"epsilon\", \"a\"]\n",
    "                            if arg in sampling]\n",
    "                    if len(args):\n",
    "                        warnings.warn('Number of samples defined as input, ' +\n",
    "                                      'ignoring arguments:', ', '.join(args))\n",
    "\n",
    "                    # Initialise the sample graphlets function\n",
    "                    sample_graphlets = sample_graphlets_probabilistic\n",
    "\n",
    "                elif (\"delta\" in sampling or \"epsilon\" in sampling\n",
    "                        or \"a\" in sampling):\n",
    "                    # Otherwise if delta exists\n",
    "                    delta = sampling.get(\"delta\", 0.05)\n",
    "                    # or epsilon\n",
    "                    epsilon = sampling.get(\"epsilon\", 0.05)\n",
    "                    # or a\n",
    "                    a = sampling.get(\"a\", -1)\n",
    "\n",
    "                    # check the fit constraints\n",
    "                    if delta > 1 or delta < 0:\n",
    "                        raise TypeError('delta must be in the range (0,1)')\n",
    "\n",
    "                    if epsilon > 1 or epsilon < 0:\n",
    "                        raise TypeError('epsilon must be in the range (0,1)')\n",
    "\n",
    "                    if type(a) is not int:\n",
    "                        raise TypeError('a must be an integer')\n",
    "                    elif a == 0:\n",
    "                        raise TypeError('a cannot be zero')\n",
    "                    elif a < -1:\n",
    "                        raise TypeError('negative a smaller than -1 have '\n",
    "                                        'no meaning')\n",
    "\n",
    "                    if(a == -1):\n",
    "                        fallback_map = {1: 1, 2: 2, 3: 4, 4: 8, 5: 19, 6: 53,\n",
    "                                        7: 209, 8: 1253, 9: 13599}\n",
    "                        if(k > 9):\n",
    "                            warnings.warn(\n",
    "                                'warning for such size number of isomorphisms '\n",
    "                                'is not known - interpolation on know values '\n",
    "                                'will be used')\n",
    "                            # Use interpolations\n",
    "\n",
    "                            isomorphism_prediction = \\\n",
    "                                interp1d(list(fallback_map.keys()),\n",
    "                                         list(itervalues(fallback_map)),\n",
    "                                         kind='cubic')\n",
    "                            a = isomorphism_prediction(k)\n",
    "                        else:\n",
    "                            a = fallback_map[k]\n",
    "\n",
    "                    # and calculate number of samples\n",
    "                    n_samples = math.ceil(2*(a*np.log10(2) +\n",
    "                                          np.log10(1/delta))/(epsilon**2))\n",
    "\n",
    "                    sample_graphlets = sample_graphlets_probabilistic\n",
    "                else:\n",
    "                    raise ValueError('sampling doesn\\'t have a valid dictionary format')\n",
    "            else:\n",
    "                raise TypeError('sampling can either be a dictionary or None')\n",
    "            self.sample_graphlets_ = sample_graphlets\n",
    "            self.k_ = k\n",
    "            self.n_samples_ = n_samples\n",
    "        self._initialized[\"sampling\"] = True\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Calculate the kernel matrix, between given and fitted dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            Each element must be an iterable with at most three features and at\n",
    "            least one. The first that is obligatory is a valid graph structure\n",
    "            (adjacency matrix or edge_dictionary) while the second is\n",
    "            node_labels and the third edge_labels (that fitting the given graph\n",
    "            format).\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K : numpy array, shape = [n_targets, n_input_graphs]\n",
    "            corresponding to the kernel matrix, a calculation between\n",
    "            all pairs of graphs between target an features\n",
    "\n",
    "        \"\"\"\n",
    "        self._method_calling = 3\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['X'])\n",
    "\n",
    "        # Input validation and parsing\n",
    "        if X is None:\n",
    "            raise ValueError('transform input cannot be None')\n",
    "        else:\n",
    "            Y = self.parse_input(X)\n",
    "\n",
    "        # Transform - calculate kernel matrix\n",
    "        try:\n",
    "            check_is_fitted(self, ['_phi_X'])\n",
    "            phi_x = self._phi_X\n",
    "        except NotFittedError:\n",
    "            phi_x = np.zeros(shape=(self._nx, len(self._graph_bins)))\n",
    "            for ((i, j), v) in iteritems(self.X):\n",
    "                phi_x[i, j] = v\n",
    "            self._phi_X = phi_x\n",
    "        phi_y = np.zeros(shape=(self._ny, len(self._graph_bins) +\n",
    "                                len(self._Y_graph_bins)))\n",
    "        for ((i, j), v) in iteritems(Y):\n",
    "            phi_y[i, j] = v\n",
    "\n",
    "        # store _phi_Y for independent (of normalization arg diagonal-calls)\n",
    "        self._phi_Y = phi_y\n",
    "        km = np.dot(phi_y[:, :len(self._graph_bins)], phi_x.T)\n",
    "        self._is_transformed = True\n",
    "        if self.normalize:\n",
    "            X_diag, Y_diag = self.diagonal()\n",
    "            km /= np.sqrt(np.outer(Y_diag, X_diag))\n",
    "        return km\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"Fit and transform, on the same dataset.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            Each element must be an iterable with at most three features and at\n",
    "            least one. The first that is obligatory is a valid graph structure\n",
    "            (adjacency matrix or edge_dictionary) while the second is\n",
    "            node_labels and the third edge_labels (that fitting the given graph\n",
    "            format). If None the kernel matrix is calculated upon fit data.\n",
    "            The test samples.\n",
    "\n",
    "        y : None\n",
    "            There is no need of a target in a transformer, yet the pipeline API\n",
    "            requires this parameter.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        K : numpy array, shape = [n_input_graphs, n_input_graphs]\n",
    "            corresponding to the kernel matrix, a calculation between\n",
    "            all pairs of graphs between target an features\n",
    "\n",
    "        \"\"\"\n",
    "        self._method_calling = 2\n",
    "        self.fit(X)\n",
    "\n",
    "        # calculate feature matrices.\n",
    "        phi_x = np.zeros(shape=(self._nx, len(self._graph_bins)))\n",
    "        for ((i, j), v) in iteritems(self.X):\n",
    "            phi_x[i, j] = v\n",
    "\n",
    "        # Transform - calculate kernel matrix\n",
    "        self._phi_X = phi_x\n",
    "        km = phi_x.dot(phi_x.T)\n",
    "\n",
    "        self._X_diag = np.diagonal(km)\n",
    "        if self.normalize:\n",
    "            return np.divide(km, np.sqrt(np.outer(self._X_diag, self._X_diag)))\n",
    "        else:\n",
    "            return km\n",
    "\n",
    "    def diagonal(self):\n",
    "        \"\"\"Calculate the kernel matrix diagonal for fitted data.\n",
    "\n",
    "        A funtion called on transform on a seperate dataset to apply\n",
    "        normalization on the exterior.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        None.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_diag : np.array\n",
    "            The diagonal of the kernel matrix, of the fitted data.\n",
    "            This consists of kernel calculation for each element with itself.\n",
    "\n",
    "        Y_diag : np.array\n",
    "            The diagonal of the kernel matrix, of the transformed data.\n",
    "            This consists of kernel calculation for each element with itself.\n",
    "\n",
    "        \"\"\"\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self, ['_phi_X'])\n",
    "        try:\n",
    "            check_is_fitted(self, ['_X_diag'])\n",
    "        except NotFittedError:\n",
    "            # Calculate diagonal of X\n",
    "            self._X_diag = np.sum(np.square(self._phi_X), axis=1)\n",
    "\n",
    "        try:\n",
    "            # If transform has happened return Y\n",
    "            check_is_fitted(self, ['_phi_Y'])\n",
    "            Y_diag = np.sum(np.square(self._phi_Y), axis=1)\n",
    "            return self._X_diag, Y_diag\n",
    "        except NotFittedError:\n",
    "            # Calculate diagonal of X\n",
    "            return self._X_diag\n",
    "\n",
    "    def parse_input(self, X):\n",
    "        \"\"\"Parse and create features for graphlet_sampling kernel.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : iterable\n",
    "            For the input to pass the test, we must have:\n",
    "            Each element must be an iterable with at most three features and at\n",
    "            least one. The first that is obligatory is a valid graph structure\n",
    "            (adjacency matrix or edge_dictionary) while the second is\n",
    "            node_labels and the third edge_labels (that correspond to the given\n",
    "            graph format). A valid input also consists of graph type objects.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        local_values : dict\n",
    "            A dictionary of pairs between each input graph and a bins where the\n",
    "            sampled graphlets have fallen.\n",
    "\n",
    "        \"\"\"\n",
    "        if not isinstance(X, collections.Iterable):\n",
    "            raise TypeError('input must be an iterable\\n')\n",
    "        else:\n",
    "            i = -1\n",
    "            if self._method_calling == 1:\n",
    "                self._graph_bins = dict()\n",
    "            elif self._method_calling == 3:\n",
    "                self._Y_graph_bins = dict()\n",
    "            local_values = dict()\n",
    "            for (idx, x) in enumerate(iter(X)):\n",
    "                is_iter = False\n",
    "                if isinstance(x, collections.Iterable):\n",
    "                    is_iter = True\n",
    "                    x = list(x)\n",
    "                if type(x) is Graph:\n",
    "                    A = x.get_adjacency_matrix()\n",
    "                elif is_iter and len(x) in [0, 1, 2, 3]:\n",
    "                    if len(x) == 0:\n",
    "                        warnings.warn('Ignoring empty element on ' +\n",
    "                                      'index: '+str(idx))\n",
    "                        continue\n",
    "                    else:\n",
    "                        A = Graph(x[0], {}, {},\n",
    "                                  self._graph_format).get_adjacency_matrix()\n",
    "                else:\n",
    "                    raise TypeError('each element of X must be either a ' +\n",
    "                                    'graph or an iterable with at least 1 ' +\n",
    "                                    'and at most 3 elements\\n')\n",
    "                A = (A > 0).astype(int)\n",
    "                i += 1\n",
    "                # sample graphlets based on the initialized method\n",
    "                samples = self.sample_graphlets_(A, self.k_, self.n_samples_, self.random_state_)\n",
    "\n",
    "                if self._method_calling == 1:\n",
    "                    for (j, sg) in enumerate(samples):\n",
    "                        # add the graph to an isomorphism class\n",
    "                        if len(self._graph_bins) == 0:\n",
    "                            self._graph_bins[0] = sg\n",
    "                            local_values[(i, 0)] = 1\n",
    "                        else:\n",
    "                            newbin = True\n",
    "                            for k in range(len(self._graph_bins)):\n",
    "                                if self._graph_bins[k].isomorphic(sg):\n",
    "                                    newbin = False\n",
    "                                    if (i, k) not in local_values:\n",
    "                                        local_values[(i, k)] = 1\n",
    "                                    local_values[(i, k)] += 1\n",
    "                                    break\n",
    "                            if newbin:\n",
    "                                local_values[(i, len(self._graph_bins))] = 1\n",
    "                                self._graph_bins[len(self._graph_bins)] = sg\n",
    "                elif self._method_calling == 3:\n",
    "                    for (j, sg) in enumerate(samples):\n",
    "                        # add the graph to an isomorphism class\n",
    "                        newbin = True\n",
    "                        for k in range(len(self._graph_bins)):\n",
    "                            if self._graph_bins[k].isomorphic(sg):\n",
    "                                newbin = False\n",
    "                                if (i, k) not in local_values:\n",
    "                                    local_values[(i, k)] = 1\n",
    "                                local_values[(i, k)] += 1\n",
    "                                break\n",
    "                        if newbin:\n",
    "                            if len(self._Y_graph_bins) == 0:\n",
    "                                self._Y_graph_bins[0] = sg\n",
    "                                local_values[(i, len(self._graph_bins))] = 1\n",
    "                            else:\n",
    "                                newbin_Y = True\n",
    "                                start = len(self._graph_bins)\n",
    "                                start_Y = len(self._Y_graph_bins)\n",
    "                                for l in range(start_Y):\n",
    "                                    if self._Y_graph_bins[l].isomorphic(sg):\n",
    "                                        newbin_Y = False\n",
    "                                        bin_key = (i, l + start)\n",
    "                                        if bin_key not in local_values:\n",
    "                                            local_values[bin_key] = 1\n",
    "                                        local_values[bin_key] += 1\n",
    "                                        break\n",
    "                                if newbin_Y:\n",
    "                                    idx = start + start_Y\n",
    "                                    local_values[(i, idx)] = 1\n",
    "                                    self._Y_graph_bins[start_Y] = sg\n",
    "\n",
    "            if i == -1:\n",
    "                raise ValueError('parsed input is empty')\n",
    "\n",
    "            if self._method_calling == 1:\n",
    "                self._nx = i+1\n",
    "            elif self._method_calling == 3:\n",
    "                self._ny = i+1\n",
    "            return local_values\n",
    "\n",
    "\n",
    "\n",
    "def sample_graphlets_probabilistic(A, k, n_samples, rs):\n",
    "    \"\"\"Propabilistical sampling of n_samples of 3..k sized graphs.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.array\n",
    "        A binary array defining a certain graph.\n",
    "\n",
    "    k : int\n",
    "        The maximum dimension of the sampled graphlets.\n",
    "\n",
    "    n_samples : int\n",
    "        Sets the value of randomly drawn random samples,\n",
    "        from sizes between 3..k\n",
    "\n",
    "    rs : RandomState\n",
    "        A RandomState object handling all randomness of the class.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graphlets : generator\n",
    "        Returns a generator of sampled graphlets (as pynauty graphs),\n",
    "        from sizes between 3..k.\n",
    "\n",
    "    \"\"\"\n",
    "    s = list(range(A.shape[0]))\n",
    "    min_r, max_r = min(k, A.shape[0]), min(k, A.shape[0])\n",
    "    if min_r == max_r:\n",
    "        def rsamp(*args):\n",
    "            return min_r\n",
    "    else:\n",
    "        def rsamp(*args):\n",
    "            return rs.randint(min_r, max_r+1)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "        index_rand = rs.choice(s, rsamp(), replace=False)\n",
    "        Q = A[index_rand, :][:, index_rand]\n",
    "        yield bGraph(Q.shape[0], zip(*np.where(Q == 1)))\n",
    "\n",
    "\n",
    "def sample_graphlets_all_connected(A, k):\n",
    "    \"\"\"All the connected graphlets of size k of a given graph.\n",
    "\n",
    "    The implemented algorithm can be found in :cite:`Karakashian2013AnAF` as `ConSubg`.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    A : np.array\n",
    "        A binary array defining a certain graph.\n",
    "\n",
    "    k : int\n",
    "        The maximum dimension of the sampled graphlets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    graphlets : generator\n",
    "        Returns a generator of sampled graphlets (as pynauty graphs),\n",
    "        of size k.\n",
    "\n",
    "    \"\"\"\n",
    "    G = {i: set(np.where(A[i, :] != 0)[0]) for i in range(A.shape[0])}\n",
    "    for s in ConSubg(G, k, np.all(A == A.T)):\n",
    "        enum = {j: i for i, j in enumerate(s)}\n",
    "        yield bGraph(len(s), iter((enum[i], enum[j]) for i in s for j in s & G[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do 3\n",
      "computing kernel matrix for the training set\n",
      " time :--- 0.21831321716308594 seconds ---\n",
      "do 4\n",
      "computing kernel matrix for the training set\n",
      " time :--- 0.274172306060791 seconds ---\n",
      "do 5\n",
      "computing kernel matrix for the training set\n",
      " time :--- 0.450930118560791 seconds ---\n",
      "do 6\n",
      "computing kernel matrix for the training set\n",
      " time :--- 0.9399170875549316 seconds ---\n",
      "do 7\n",
      "computing kernel matrix for the training set\n",
      " time :--- 1.8633766174316406 seconds ---\n",
      "do 8\n",
      "computing kernel matrix for the training set\n",
      " time :--- 4.096047639846802 seconds ---\n",
      "do 9\n",
      "computing kernel matrix for the training set\n",
      " time :--- 7.485494375228882 seconds ---\n",
      "do 10\n",
      "computing kernel matrix for the training set\n",
      " time :--- 9.624165773391724 seconds ---\n",
      "do 11\n",
      "computing kernel matrix for the training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-39f5985b5efd>:148: UserWarning: graphlets are too big - computation may be slow\n",
      "  warnings.warn('graphlets are too big - '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time :--- 10.04696249961853 seconds ---\n",
      "do 12\n",
      "computing kernel matrix for the training set\n",
      " time :--- 10.184511661529541 seconds ---\n",
      "do 13\n",
      "computing kernel matrix for the training set\n",
      " time :--- 10.767987966537476 seconds ---\n",
      "do 14\n",
      "computing kernel matrix for the training set\n",
      " time :--- 11.051629304885864 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k_range = np.arange(3, 15)\n",
    "results_time=np.array([])\n",
    "\n",
    "for (k_ind, k) in enumerate(k_range):\n",
    "    print(\"do {}\".format(k))\n",
    "    (G_train,y_train) ,(G_test, y_test) = dataset_loading().generate_SBM(Graphs_num=2, test_size=1, mult_factor=1.5)\n",
    "    # Uses the shortest path kernel to generate the kernel matrices\n",
    "    kernel = MyGraphletSampling(k=int(k), sampling={'n_samples':2000})\n",
    "    print('computing kernel matrix for the training set')\n",
    "    #kernel = ShortestPath(normalize=True)\n",
    "    start_time=time.time()\n",
    "    K_train = kernel.fit_transform(G_train)\n",
    "    results_time=np.append(results_time,float(time.time() - start_time))\n",
    "    print(\" time :--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff6de229b50>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(k_range, results_time/2000)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Graphlet kernel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
